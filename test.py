import os
NOTION_API_KEY = os.getenv("NOTION_API_KEY")  # é€™æ¨£ GitHub Actions æœƒè‡ªå‹•è®€å–é‡‘é‘°

import requests
import json
from datetime import datetime
import urllib.parse

# âœ… è¨­å®š Notion API é‡‘é‘° & è³‡æ–™åº« ID
DATABASE_ID = "197cc8ff5d1c80f08a8cc2e28a1e2ab3"

DISCORD_WEBHOOK_URL = "https://discord.com/api/webhooks/1340390610627989584/Mn94r688fJHn-YU5za1_t0XhjrCsWF8x-eukAOdF6PRFtpjfQioZxE2G-_ZU1mIIkXtY"

import feedparser  # éœ€è¦å®‰è£ feedparser å¥—ä»¶
import urllib.parse
from datetime import datetime

# âœ… API ç«¯é»ï¼ˆç¢ºä¿ DATABASE_ID æ­£ç¢ºï¼‰
url = f"https://api.notion.com/v1/databases/{DATABASE_ID}"


# âœ… è¨­å®šè«‹æ±‚æ¨™é ­
headers = {
    "Authorization": f"Bearer {NOTION_API_KEY}",
    "Content-Type": "application/json; charset=utf-8",
    "Notion-Version": "2022-06-28",
    "Accept-Charset": "utf-8"
}

# âœ… è¨­å®šä½ è¦æŸ¥è©¢çš„å…¬å¸ï¼ˆå°ç£ + åœ‹å¤–ï¼‰
COMPANIES = ["Tesla", "Apple", "Microsoft", "Nvidia", "Amazon", "å°ç©é›»", "é´»æµ·", "è¯ç™¼ç§‘", "é•·æ¦®æµ·é‹", "å¤§ç«‹å…‰"]


# âœ… ç”¢ç”Ÿ Google News RSS æœå°‹ URL
query = " OR ".join(COMPANIES)  # è®“ Google News RSS æœå°‹é€™äº›é—œéµå­—
encoded_query = urllib.parse.quote(query)  # è½‰æ›æˆ URL å¯ç”¨æ ¼å¼
NEWS_FEED_URL = f"https://news.google.com/rss/search?q={encoded_query}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"

# âœ… è§£æ Google News RSS
def fetch_google_news(company):
    encoded_company = urllib.parse.quote(company, safe="", encoding="utf-8")  # âœ… å¼·åˆ¶ä½¿ç”¨ UTF-8
    if company in ["å°ç©é›»", "é´»æµ·", "è¯ç™¼ç§‘", "é•·æ¦®æµ·é‹", "å¤§ç«‹å…‰"]:
        rss_url = f"https://news.google.com/rss/search?q={encoded_company}+è‚¡åƒ¹&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    else:
        rss_url = f"https://news.google.com/rss/search?q={encoded_company}+stock&hl=en-US&gl=US&ceid=US:en"
    
    news_feed = feedparser.parse(rss_url)
    news_list = []
    
    for entry in news_feed.entries[:1]:  # é™åˆ¶æŠ“å– 5 å‰‡æ–°è
        title = entry.title.encode("utf-8", "ignore").decode("utf-8")  # âœ… å¼·åˆ¶ UTF-8
        link = entry.link.encode("utf-8", "ignore").decode("utf-8")  # âœ… ç¢ºä¿ URL æ­£ç¢º
        published_date = datetime.strptime(entry.published, "%a, %d %b %Y %H:%M:%S %Z").strftime("%Y-%m-%d")
        
        news_list.append({"title": title, "url": link, "date": published_date, "company": company})
    for news in news_list:
         print(news["title"], news["url"], news["date"])

    return news_list

# âœ… å–å¾—ç•¶å¤©æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
today_date = datetime.now().strftime("%Y-%m-%d")

# âœ… è§£æ RSSï¼Œç¯©é¸å‡ºã€Œç•¶å¤©æ–°èã€
def get_today_news():
    feed = feedparser.parse(NEWS_FEED_URL)
    today_news = []
    company_news_count = {company: 0 for company in COMPANIES}
    seen_news = set()  # ğŸ”¹ å­˜æ”¾ (æ¨™é¡Œ, URL) ä¾†éæ¿¾é‡è¤‡æ–°è

    for company in COMPANIES:  
        feed = feedparser.parse(NEWS_FEED_URL.format(company=company))

        for entry in feed.entries:
            # **å¦‚æœæ–°èæ²’æœ‰æ—¥æœŸï¼Œç›´æ¥è·³é**
            if "published_parsed" not in entry:
                continue
                
                news_date = datetime(*entry.published_parsed[:3]).strftime("%Y-%m-%d")
                
    for entry in feed.entries:
        # ğŸŸ¢ ç¢ºä¿ `published_parsed` æ­£ç¢ºè§£ææ™‚é–“
            if hasattr(entry, 'published_parsed'):
                news_date = datetime(*entry.published_parsed[:3]).strftime("%Y-%m-%d")
            
            if news_date == today_date:  # åªæŠ“ç•¶å¤©çš„æ–°è
                for company in COMPANIES:
                    if company in entry.title and company_news_count[company] < 2:
                        today_news.append({
                            "title": entry.title,
                            "url": entry.link,
                            "date": news_date
                        })
                        
    for company in COMPANIES:    
            feed = feedparser.parse(NEWS_FEED_URL.format(company=company))
            seen_media = set()  # è¨˜éŒ„ã€Œå·²è™•ç†éçš„æ–°èåª’é«”ã€

            for entry in feed.entries:
                news_date = datetime(*entry.published_parsed[:3]).strftime("%Y-%m-%d")
            
                if news_date == today_date:    
                    media_name = entry.source.title if "source" in entry else "Unknown"  # ç²å–æ–°èåª’é«”åç¨±
                    news_key = f"{company}-{media_name}"  # å»ºç«‹å”¯ä¸€éµå€¼
                 
                    if news_key not in seen_media:  # å¦‚æœé€™å€‹æ–°èåª’é«”æ²’è¢«è™•ç†é
                        today_news.append({
                            "company": company,
                            "media": media_name,
                            "title": entry.title,
                            "url": entry.link,
                            "date": news_date
                         })
                        seen_media.add(news_key)   # æ¨™è¨˜ç‚ºå·²è™•ç†

                        company_news_count[company] += 1
                        break  # é˜²æ­¢ä¸€ç¯‡æ–°èè¢«è¨˜éŒ„å¤š

    print(f"ğŸ“… ä»Šæ—¥ç¯©é¸å¾Œçš„æ–°èæ•¸é‡ï¼š{len(today_news)}")  # Debug
    return today_news

# âœ… æ–°å¢æ–°èåˆ° Notion
def add_news_to_notion(title, url, date):
    notion_url = "https://api.notion.com/v1/pages"
    
    data = {
        "parent": {"database_id": DATABASE_ID},
        "properties": {
            "Name": {  
                "title": [
                    {
                        "text": {
                            "content": title
                        }
                    }
                ]
            },
            "Task": { "select": { "name": "Onboarding Flow" } },  # âœ… Task é¸æ“‡æ¬„ä½
            "Date": { "date": { "start": date } },  # âœ… æ—¥æœŸæ¬„ä½
            "URL": { "url": url }  # âœ… ç¢ºä¿é€™è£¡æ˜¯æ­£ç¢ºçš„ URL æ¬„ä½åç¨±
        }
    }
    try:
        response = requests.post(notion_url, headers=headers, json=data)
        response.raise_for_status()  # è‹¥ API å›å‚³éŒ¯èª¤ç¢¼ (å¦‚ 400/500) æœƒè‡ªå‹•æ‹‹å‡ºä¾‹å¤–

        # âœ… é€ Discord Webhook é€šçŸ¥
        send_discord_notification(title, url)

        return response.status_code, response.json()
    except requests.exceptions.RequestException as e:
        print(f"âŒ æ–°å¢æ–°èå¤±æ•—ï¼š{title}")
        print(f"ğŸ”´ éŒ¯èª¤è¨Šæ¯ï¼š{e}")
        return None, None  # é¿å…ç¨‹å¼å´©æ½°

# âœ… ç™¼é€æ–°èåˆ° Discord
def send_discord_notification(title, url):
    message = {
        "content": f"ğŸ“¢ **{title}**\nğŸ”— {url}"
    }
    response = requests.post(DISCORD_WEBHOOK_URL, json=message)
    if response.status_code == 204:
        print(f"âœ… å·²ç™¼é€æ–°èåˆ° Discordï¼š{title}")
    else:
        print(f"âŒ Discord ç™¼é€å¤±æ•—ï¼Œç‹€æ…‹ç¢¼ï¼š{response.status_code}")
    response = requests.post(DISCORD_WEBHOOK_URL, headers=headers, json=message)  # âœ… ä½¿ç”¨ `json=data`

    if response.status_code == 200:
        print(f"âœ… æˆåŠŸæ–°å¢æ–°è: {title}")
    else:
        print(f"âŒ æ–°å¢æ–°èå¤±æ•—: {title}ï¼ŒéŒ¯èª¤ç¢¼: {response.status_code}")
        print("ğŸ”¹ API å›æ‡‰å…§å®¹ï¼š", response.text.encode("utf-8", "ignore").decode("utf-8"))



# âœ… æŠ“å–å¤šå®¶å…¬å¸æ–°èä¸¦å¯«å…¥ Notion
for company in COMPANIES:
    news_list = fetch_google_news(company)
    for news in news_list:
        add_news_to_notion(news["title"], news["url"], news["date"])
for news in news_list:
     print(news["title"], news["url"], news["date"])

news_list = get_today_news()

if news_list:
    print(f"âœ… ä»Šå¤©æœ‰ {len(news_list)} å‰‡æ–°èï¼Œé–‹å§‹å¯«å…¥ Notion...")
    for news in news_list:
        print(f"âœ… æˆåŠŸæ–°å¢æ–°èï¼š{news['title']}")
else:
    print("ğŸš« ä»Šå¤©æ²’æœ‰æ–°èï¼Œä¸å¯«å…¥ Notion")
